{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from groq import Groq\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fast language models are crucial in today's natural language processing (NLP) landscape, and their importance can be attributed to several factors:\n",
      "\n",
      "1. **Real-time Applications**: Fast language models enable real-time applications such as chatbots, virtual assistants, and language translation systems to respond quickly and efficiently. This is particularly important in scenarios where timely responses are critical, such as customer support or emergency services.\n",
      "2. **Low-Latency Requirements**: Many modern applications, like voice assistants, require language models to process and respond to user input within a few hundred milliseconds. Fast language models can meet these low-latency requirements, ensuring a seamless user experience.\n",
      "3. **Scalability**: Fast language models can handle large volumes of data and user requests, making them essential for large-scale NLP applications, such as language translation platforms or social media analytics tools.\n",
      "4. **Energy Efficiency**: Fast language models can reduce the computational resources required for NLP tasks, leading to energy efficiency and cost savings. This is particularly important for edge devices, mobile devices, or data centers with limited power budgets.\n",
      "5. **Improved User Experience**: Fast language models can provide instant feedback, enabling users to interact more naturally with language-based systems. This leads to a better user experience, increased engagement, and higher adoption rates.\n",
      "6. **Competitive Advantage**: In today's fast-paced digital landscape, companies that can respond quickly and efficiently to user input can gain a competitive advantage over those that cannot.\n",
      "7. **Edge AI and IoT**: Fast language models are essential for edge AI and IoT applications, where devices have limited computational resources and require real-time processing capabilities.\n",
      "8. **Multimodal Interaction**: Fast language models can enable seamless multimodal interaction, where users can interact with systems using voice, text, or gestures, and receive instant responses.\n",
      "9. **Accessibility**: Fast language models can improve accessibility for people with disabilities, such as those who rely on speech-to-text systems or language translation tools.\n",
      "10. **Research and Development**: Fast language models can accelerate research and development in NLP, enabling scientists to explore new ideas, test hypotheses, and iterate on models more quickly.\n",
      "\n",
      "To achieve fast language models, researchers and developers employ various techniques, including:\n",
      "\n",
      "1. Model pruning and knowledge distillation\n",
      "2. Quantization and binarization\n",
      "3. Efficient neural network architectures\n",
      "4. Parallel processing and distributed computing\n",
      "5. Caching and memoization\n",
      "6. Optimized algorithms and data structures\n",
      "7. Specialized hardware, such as TPUs or GPUs\n",
      "\n",
      "By leveraging these techniques, fast language models can unlock new possibilities in NLP, enabling more efficient, scalable, and responsive applications that transform the way humans interact with machines.\n"
     ]
    }
   ],
   "source": [
    "client = Groq(api_key=os.environ.get(\"GROQ_API_KEY\"))\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Explain the importance of fast language models\"}\n",
    "    ],\n",
    "    model=\"llama3-70b-8192\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, client: Groq, system: str = \"\") -> None:\n",
    "        self.client = client\n",
    "        self.system = system\n",
    "        self.messages: list = []\n",
    "        if self.system:\n",
    "            self.messages.append({\"role\": \"system\", \"content\": system})\n",
    "\n",
    "    def __call__(self, message=\"\"):\n",
    "        if message:\n",
    "            self.messages.append({\"role\": \"user\", \"content\": message})\n",
    "        result = self.execute()\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": result})\n",
    "        return result\n",
    "\n",
    "    def execute(self):\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"llama3-70b-8192\", messages=self.messages\n",
    "        )\n",
    "        return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You run in a loop of Thought, Action, PAUSE, Observation.\n",
    "At the end of the loop you output an Answer\n",
    "Use Thought to describe your thoughts about the question you have been asked.\n",
    "Use Action to run one of the actions available to you - then return PAUSE.\n",
    "Observation will be the result of running those actions.\n",
    "\n",
    "Your available actions are:\n",
    "\n",
    "calculate:\n",
    "e.g. calculate: 4 * 7 / 3\n",
    "Runs a calculation and returns the number - uses Python so be sure to use floating point syntax if necessary\n",
    "\n",
    "get_planet_mass:\n",
    "e.g. get_planet_mass: Earth\n",
    "returns weight of the planet in kg\n",
    "\n",
    "Example session:\n",
    "\n",
    "Question: What is the mass of Earth times 2?\n",
    "Thought: I need to find the mass of Earth\n",
    "Action: get_planet_mass: Earth\n",
    "PAUSE \n",
    "\n",
    "You will be called again with this:\n",
    "\n",
    "Observation: 5.972e24\n",
    "\n",
    "Thought: I need to multiply this by 2\n",
    "Action: calculate: 5.972e24 * 2\n",
    "PAUSE\n",
    "\n",
    "You will be called again with this: \n",
    "\n",
    "Observation: 1,1944×10e25\n",
    "\n",
    "If you have the answer, output it as the Answer.\n",
    "\n",
    "Answer: The mass of Earth times 2 is 1,1944×10e25.\n",
    "\n",
    "Now it's your turn:\n",
    "\"\"\".strip()\n",
    "\n",
    "\n",
    "def calculate(operation: str) -> float:\n",
    "    return eval(operation)\n",
    "\n",
    "\n",
    "def get_planet_mass(planet) -> float:\n",
    "    match planet.lower():\n",
    "        case \"earth\":\n",
    "            return 5.972e24\n",
    "        case \"jupiter\":\n",
    "            return 1.898e27\n",
    "        case \"mars\":\n",
    "            return 6.39e23\n",
    "        case \"mercury\":\n",
    "            return 3.285e23\n",
    "        case \"neptune\":\n",
    "            return 1.024e26\n",
    "        case \"saturn\":\n",
    "            return 5.683e26\n",
    "        case \"uranus\":\n",
    "            return 8.681e25\n",
    "        case \"venus\":\n",
    "            return 4.867e24\n",
    "        case _:\n",
    "            return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "neil_tyson = Agent(client=client, system=system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def loop(max_iterations=10, query: str = \"\"):\n",
    "\n",
    "    agent = Agent(client=client, system=system_prompt)\n",
    "\n",
    "    tools = [\"calculate\", \"get_planet_mass\"]\n",
    "\n",
    "    next_prompt = query\n",
    "\n",
    "    i = 0\n",
    "  \n",
    "    while i < max_iterations:\n",
    "        i += 1\n",
    "        result = agent(next_prompt)\n",
    "        print(result)\n",
    "\n",
    "        if \"PAUSE\" in result and \"Action\" in result:\n",
    "            action = re.findall(r\"Action: ([a-z_]+): (.+)\", result, re.IGNORECASE)\n",
    "            chosen_tool = action[0][0]\n",
    "            arg = action[0][1]\n",
    "\n",
    "            if chosen_tool in tools:\n",
    "                result_tool = eval(f\"{chosen_tool}('{arg}')\")\n",
    "                next_prompt = f\"Observation: {result_tool}\"\n",
    "\n",
    "            else:\n",
    "                next_prompt = \"Observation: Tool not found\"\n",
    "\n",
    "            print(next_prompt)\n",
    "            continue\n",
    "\n",
    "        if \"Answer\" in result:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: Let's start by calculating the total cost of the fruits I've already bought.\n",
      "\n",
      "Action: calculate: 8 * 0.5 + 5 * 0.25\n",
      "PAUSE\n",
      "Observation: 5.25\n",
      "Thought: I've already spent 5.25 pounds, and I want to spend the remaining 14.75 pounds (20 - 5.25) on more bananas and apples.\n",
      "\n",
      "Action: calculate: 14.75 / (0.5 + 0.25)\n",
      "PAUSE\n",
      "Observation: 19.666666666666668\n",
      "Thought: This result represents the total number of fruits I can buy with the remaining money. Since I'm buying bananas and apples, I'll divide this number by 2 to find out how many of each fruit I can buy.\n",
      "\n",
      "Action: calculate: 19.666666666666668 / 2\n",
      "PAUSE\n",
      "Observation: 9.833333333333334\n",
      "Thought: Since I cannot buy a fraction of a fruit, I'll round down to the nearest whole number to find out how many bananas and apples I can buy.\n",
      "\n",
      "Action: calculate: 9\n",
      "PAUSE\n",
      "Observation: 9\n",
      "Thought: I've reached my answer. I'll buy 9 more bananas and 9 more apples.\n",
      "\n",
      "Answer: I'll buy 17 bananas (8 + 9) and 14 apples (5 + 9).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#loop(query=\"What is the mass of Earth plus the mass of Saturn and all of that times 2?\")\n",
    "#loop(query=\"You go and shop 12 bananas and 5 apple. The price of bana per unit is 5 penny. Total bill is 1.1 pounds. What is apple per unit?\")\n",
    "#loop(query=\"You go and shop and spend 20 pounds buying bananas and apples. The 8 bananas cost 0.5 per unit. The the 5 apples cost 0.25 per unit . Now shop the two fruits such that all the menoey is spent. Give how much bananas and apples are bought?\")\n",
    "loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
